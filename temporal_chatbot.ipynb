{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-2J1UOMRxO5"
      },
      "source": [
        "# Required Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gehY6ri7_efR"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import spacy\n",
        "import json\n",
        "import re\n",
        "import pickle\n",
        "import optuna\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import DataLoader\n",
        "#from torchtune import Trial, RandomSearchScheduler, Reporter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FayqHTZ4FWNi"
      },
      "outputs": [],
      "source": [
        "! pip install datasets\n",
        "! pip install transformers[torch]\n",
        "! pip install tokenizers\n",
        "! pip install evaluate\n",
        "! pip install rouge_score\n",
        "! pip install sentencepiece\n",
        "! pip install huggingface_hub\n",
        "!pip install timexy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYnmKA59Fj95"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import evaluate\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "from transformers import T5Tokenizer, DataCollatorForSeq2Seq,TFMT5ForConditionalGeneration, MT5Tokenizer, AutoModelForSeq2SeqLM\n",
        "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoTokenizer\n",
        "from transformers import TrainingArguments, Trainer, T5Tokenizer, T5ForConditionalGeneration\n",
        "from datasets import Dataset, DatasetDict,load_dataset\n",
        "import timexy\n",
        "from timexy import Timexy\n",
        "from timexy import rule\n",
        "from timexy.languages import en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evUA07vrGWiM",
        "scrolled": true,
        "outputId": "ef807e49-c100-4866-f1f6-e402469043f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<timexy.timexy.Timexy at 0x7f52dea22ad0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Optionally add config if varying from default values\n",
        "config = {\n",
        "    \"kb_id_type\": \"timex3\",  # possible values: 'timex3'(default), 'timestamp'\n",
        "    \"label\": \"timexy\",       # default: 'timexy'\n",
        "    \"overwrite\": False       # default: False\n",
        "}\n",
        "nlp.add_pipe(\"timexy\", config=config, before=\"ner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4WXzlCs_kil"
      },
      "outputs": [],
      "source": [
        "output_dir = \"./results\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANQvEBCg_kin"
      },
      "outputs": [],
      "source": [
        "chkpnt = './input/checkpoints/chkpnt1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVONXWH2_kiq"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM6MKyGC_kis"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"google/flan-t5-base\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wfq3VJsE_kit"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('dataset.csv')\n",
        "testing = pd.read_csv('testing_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMgNMaxQSFzZ"
      },
      "source": [
        "# Model Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkJZrKRUH5NK"
      },
      "outputs": [],
      "source": [
        "# Run it the first time\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "model.save_pretrained(chkpnt)\n",
        "tokenizer.save_pretrained(chkpnt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QShoCqZqXQvy"
      },
      "outputs": [],
      "source": [
        "# Training Arguments\n",
        "L_RATE = 3e-4\n",
        "BATCH_SIZE = 4\n",
        "PER_DEVICE_EVAL_BATCH = 2\n",
        "WEIGHT_DECAY = 0.01\n",
        "SAVE_TOTAL_LIM = 3\n",
        "NUM_EPOCHS = 5\n",
        "drop_out = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yNYPDfvJA_Q"
      },
      "outputs": [],
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(chkpnt)\n",
        "tokenizer = T5Tokenizer.from_pretrained(chkpnt)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "model.config.dropout_rate = drop_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQhB8UHuJyTc"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "   output_dir=output_dir,\n",
        "   evaluation_strategy=\"epoch\",\n",
        "  #  save_steps=num_train_steps_per_epoch,\n",
        "   learning_rate=L_RATE,\n",
        "   per_device_train_batch_size=BATCH_SIZE,\n",
        "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
        "   weight_decay=WEIGHT_DECAY,\n",
        "   save_total_limit=SAVE_TOTAL_LIM,\n",
        "   num_train_epochs=NUM_EPOCHS,\n",
        "   predict_with_generate=True,\n",
        "   push_to_hub=False,\n",
        "   logging_dir=f\"{output_dir}/logs\",  # TensorBoard logs directory\n",
        "   logging_steps=10,  # Adjust to control how often to log metrics\n",
        "   report_to=\"tensorboard\"  # Report metrics to TensorBoard\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJLEMFjWy6rQ"
      },
      "outputs": [],
      "source": [
        "def preprocess_fun(batch):\n",
        "  prefix = \"Generate: \" # to inform the model to generate on the given input\n",
        "  clean_batch=[]\n",
        "  check=[]\n",
        "  for i in batch['Inputs']:\n",
        "    x=\"\"\n",
        "    l=[]\n",
        "    for j in i.split('\\n')[:-1]:\n",
        "      x += re.split('~__(True|False)__',j)[0] # to extract whether a sentence has temporal sense or not\n",
        "      l.append(re.split('~__(True|False)__',j)[1])\n",
        "    clean_batch.append(x)\n",
        "    check.append(l)\n",
        "\n",
        "  # The \"inputs\" are the tokenized answer:\n",
        "  inputs = [(prefix + doc) for doc in clean_batch]\n",
        "  model_inputs = tokenizer(inputs, max_length=512, truncation=True,padding='max_length')\n",
        "\n",
        "  # The \"labels\" are the tokenized outputs:\n",
        "  labels = tokenizer(text_target=batch[\"Outputs\"],\n",
        "                      max_length=512,\n",
        "                      truncation=True,\n",
        "                     padding='max_length')\n",
        "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "  return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSZsja8AHFJG"
      },
      "outputs": [],
      "source": [
        "nltk.download(\"punkt\", quiet=True)\n",
        "metric = evaluate.load(\"rouge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNCssQ4XgqjE"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    preds,refs = eval_preds\n",
        "\n",
        "    if preds.ndim == 0:\n",
        "        preds = preds.unsqueeze(0)\n",
        "\n",
        "    if refs.ndim == 0:\n",
        "        refs = refs.unsqueeze(0)\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(refs, skip_special_tokens=True)\n",
        "\n",
        "    # pred_tags = [nlp(seq) for seq in decode_preds]\n",
        "    # actual_tags = [nlp(seq) for seq in decoded_labels]\n",
        "    # err = nltk.metrics.scores.log_likelihood(actual_tags,pred_tags)\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRKZJ5ehR5Vg"
      },
      "source": [
        "# Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_iu8RLW_ki4"
      },
      "outputs": [],
      "source": [
        "# Get unique chunk identifiers\n",
        "unique_chunks = df[\"Chunk\"].unique()\n",
        "\n",
        "# Shuffle the unique chunks\n",
        "np.random.shuffle(unique_chunks)\n",
        "\n",
        "# Reorder the DataFrame based on the shuffled chunks\n",
        "df = pd.concat([df[df[\"Chunk\"] == chunk] for chunk in unique_chunks], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aRrMGUW_ki5"
      },
      "outputs": [],
      "source": [
        "c=0\n",
        "for index, row in df.iterrows():\n",
        "    if((row['Chunk'])<=1046):\n",
        "        c+=1\n",
        "train = df.iloc[:c,:]\n",
        "valid = df.iloc[c:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pY-hWAx_ki6"
      },
      "outputs": [],
      "source": [
        "trd = Dataset.from_pandas(train)\n",
        "vsd = Dataset.from_pandas(valid)\n",
        "tsd = Dataset.from_pandas(testing)\n",
        "dataset_dict = DatasetDict(\n",
        "  {\n",
        "      'train':trd,\n",
        "      'valid':vsd,\n",
        "      'test':tsd\n",
        "  }\n",
        ")\n",
        "\n",
        "tokenized_dataset = dataset_dict.map(preprocess_fun,batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDKZpHig_ki7"
      },
      "outputs": [],
      "source": [
        "with open(\"tokenized_dataset.pickle\", 'wb') as file:\n",
        "    pickle.dump(tokenized_dataset, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0F2as-3SVJp",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_bwsn_k_ki8"
      },
      "outputs": [],
      "source": [
        "perc = 80\n",
        "train_size = int((perc/100)*max(df['Chunk']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R42mhbdk_ki9"
      },
      "outputs": [],
      "source": [
        "def crossValid(k=5):\n",
        "  sm = int(np.floor(train_size/k)) # each batch size\n",
        "  split_data = [(i*sm,(i+1)*sm) for i in range(k-1)] + [((k-1)*sm,train_size)]\n",
        "  evals = [] # model evaluations and model\n",
        "\n",
        "  for split in split_data:\n",
        "    t_i,v_i = [],[]\n",
        "    for index,row in df.iterrows():\n",
        "        if(split[0]<=row['Chunk']<=split[1]):\n",
        "            v_i.append(index)\n",
        "        else:\n",
        "            t_i.append(index)\n",
        "\n",
        "    valid = df.iloc[v_i]\n",
        "    train = df.iloc[t_i]\n",
        "\n",
        "    trd = Dataset.from_pandas(train)\n",
        "    vdd = Dataset.from_pandas(valid)\n",
        "\n",
        "    dataset_dict = DatasetDict(\n",
        "      {\n",
        "          'train':trd,\n",
        "          'valid':vdd,\n",
        "          'test':tsd\n",
        "      }\n",
        "    )\n",
        "\n",
        "    tokenized_dataset = dataset_dict.map(preprocess_fun,batched=True)\n",
        "\n",
        "    model = T5ForConditionalGeneration.from_pretrained(chkpnt)\n",
        "    tokenizer = T5Tokenizer.from_pretrained(chkpnt)\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "    model.config.dropout_rate = drop_out\n",
        "\n",
        "    trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"valid\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        "    )\n",
        "    trainer.train()\n",
        "    evals.append((trainer.evaluate(),model))\n",
        "  return evals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1-QpcL6CzcZ"
      },
      "outputs": [],
      "source": [
        "evals = crossValid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7zz5ybJ_ki-"
      },
      "outputs": [],
      "source": [
        "s = f'evals_{datetime.now()}.txt'\n",
        "with open(s,'w') as f:\n",
        "    print(evals,file=f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCT7rcEc_kjD"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBiJJ_nn_kjD"
      },
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "model=model,\n",
        "args=training_args,\n",
        "train_dataset=tokenized_dataset[\"train\"],\n",
        "eval_dataset=tokenized_dataset[\"valid\"],\n",
        "tokenizer=tokenizer,\n",
        "data_collator=data_collator,\n",
        "compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVCZ0-1I_kjE"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnsyfHAqaep2"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ppzemj4t16h"
      },
      "outputs": [],
      "source": [
        "trainer.predict(tokenized_dataset[\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHDxIT8i5Ml2"
      },
      "source": [
        "# Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXLJzPgo5Njp"
      },
      "outputs": [],
      "source": [
        "c = datetime.now()\n",
        "s1 = f\"./model_lr_3e_4_drop_out_5_epoch_5/model\"\n",
        "s2 = f\"./model_lr_3e_4_drop_out_5_epoch_5/tokenizer\"\n",
        "model.save_pretrained(s1)\n",
        "tokenizer.save_pretrained(s2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "ccnIB4Dq_kjJ"
      },
      "source": [
        "# Manual Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7GrAhq9_kjK"
      },
      "outputs": [],
      "source": [
        "# Example text for generation\n",
        "text = '''\n",
        "Generate:\n",
        "How many days in a week?'''\n",
        "\n",
        "# Tokenize the text and generate output\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs)\n",
        "\n",
        "# Decode the output tokens to text\n",
        "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Generated output:\", result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "V-2J1UOMRxO5",
        "NMgNMaxQSFzZ",
        "wRKZJ5ehR5Vg",
        "G0F2as-3SVJp",
        "UCT7rcEc_kjD",
        "HnsyfHAqaep2",
        "nHDxIT8i5Ml2",
        "ccnIB4Dq_kjJ"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}